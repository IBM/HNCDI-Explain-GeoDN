{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f939a6de-3c84-4953-982e-2d1063b2f8f4",
   "metadata": {},
   "source": [
    "# GeoDN Course 2: Fundamentals of Geospatial Data and Modeling - Part 2 Geospatial Foundation Models and Workflows #\n",
    "> Copyright (c) 2024 International Business Machines Corporation\n",
    "\n",
    "> This software is released under the MIT License.\n",
    "> https://opensource.org/licenses/MIT\n",
    "\n",
    "# Section 1 - Geospatial Foundation Model: Burn scar fine-tuning\n",
    "This is an example of how to fine-tune a model to map burn scars from HLS data using the IBM Geospatial Foundation models as a starting point.  \n",
    "\n",
    "To run a fine-tuning experiment for flood mapping we will use the MMSegmentation library (https://github.ibm.com/GeoFM-Finetuning/mmsegmentation) to fine-tune a model starting from the geospatial foundation model trained on HLS data.\n",
    "\n",
    "If we are starting a new fine-tuning project, we need training data (including labels) and the pre-trained foundation model weights.  These have already been stored in an S3 bucket but are available at: https://huggingface.co/ibm-nasa-geospatial\n",
    "\n",
    "In this notebook will guide you to:\n",
    " 1. Create a fine-tuning configuration\n",
    " 2. Submitting fine-tuning job to run\n",
    " 3. Monitor and visualise the training\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe0670bf-4467-42f1-8637-e99f128ea259",
   "metadata": {},
   "source": [
    "### Prepare\n",
    "Load the `geodn.modeling` module. We also need to using the python package `os`, `json`, `glob`, `rasterio`, `numpy`, `pyplot` from `matplotlib` and `show` from `rasterio.plot`, so let's import those too.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8dec33b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from geodn.modeling import workflow\n",
    "\n",
    "import os\n",
    "import json\n",
    "import glob\n",
    "import rasterio\n",
    "import numpy as np\n",
    "from matplotlib import pyplot\n",
    "from rasterio.plot import show"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b1c382e-d453-49e2-b422-6cf4855c793b",
   "metadata": {},
   "source": [
    "### Authenticate to GeoDN\n",
    "\n",
    "To authenticate to the GeoDN services, add your username and password to the file `~/geodn-creds`, which can be found in the home folder. The format should be `your-username:your-password`. \n",
    "\n",
    "Once updated, we can use the `getToken()` function to get an authentication token which will later be used to access the GeoDN services. The `get_token()` function takes three parameters, `username`, `password` and `geodn_modeling_url`, which are your username, your password and the URL of the GeoDN backend service to connect to, respectively. \n",
    "\n",
    "These tokens will expire after 24 hours. To also return a refresh_token, pass `refresh=True` to `getToken()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59ede3be-6e48-4c98-bd0c-2e53fdf8633e",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"../..\" + '/geodn-creds', 'r') as file:\n",
    "    data = file.read().rstrip()\n",
    "    username = data.split(':')[0]\n",
    "    password = data.split(':')[1]\n",
    "\n",
    "assert username and password\n",
    "\n",
    "# Get the tokens\n",
    "id_token, access_token = workflow.get_token(username, password, geodn_modeling_url=os.environ[\"GEODN_URL\"])\n",
    "assert id_token and access_token"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51040df9",
   "metadata": {},
   "source": [
    "### Connect to GeoDN modeling\n",
    "\n",
    "And finally, we can connect to the GeoDN Modeling service. Here you will pass the token and create the connection to the GeoDN Modeling APIs. This will allow you to submit models to the cluster, check status, access logs and download files.\n",
    "\n",
    "To determine which backend service to connect to, we use the arguments `geodn_modeling_url`, `core_url` and `workflow_url`. These have been set as environment variables but can be configured if in the future you require a connection to a different backend service. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03a4e629",
   "metadata": {},
   "outputs": [],
   "source": [
    "geodn_modelling = workflow.GeoDN_Modeling(\n",
    "    bearer_token=id_token,\n",
    "    api_url=os.environ[\"GEODN_URL\"],\n",
    "    core_url=os.environ[\"GEODN_CORE_URL\"],\n",
    "    workflow_url=os.environ[\"GEODN_WORKFLOW_URL\"],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1f5f143",
   "metadata": {},
   "source": [
    "Sometimes, we can see errors returned from this function. If this is the case, it maybe that the `id_token` has expired and needs to be regenerated. Re-run the `get_token` function to generate a new token."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1832db1a-d6ed-44e4-9741-6d989d98822e",
   "metadata": {},
   "source": [
    "# 1. Creating fine-tuning configuration"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a3780e4-1241-4836-9acc-ac473b5c484c",
   "metadata": {},
   "source": [
    "\n",
    "![Fine-tune architecture](finetune_arch.png)\n",
    "\n",
    "### Brief introduction to the hyperparameters we will adapt as part of this session\n",
    "**Loss function**:\n",
    "    Both tasks we will solve as part of this exercise are binary semantic segmentation task (e.g., pixelwise classification of flood vs. background). There will be two available loss functions for the task:\n",
    "| Loss functions | Description | Code |\n",
    "| -------------- | ----------- | ---- |\n",
    "| CrossEntropyLoss | is sensitive to class imbalance but very general and a good choice for an initial training | `type='CrossEntropyLoss', use_sigmoid=False, loss_weight=1, class_weight=[0.15, 0.85]` |\n",
    "| DiceLoss | is invariant against class imbalance but tends to be more sensitive to other hyperparameters | `type='DiceLoss', use_sigmoid=False, loss_weight=1` |\n",
    "\n",
    "We observed a good performance of unweighted dice loss in our experiments.\n",
    "\n",
    "**Weighting classes** in the loss function:\n",
    "    As described above some loss functions (like CE loss) are sensitive to class imbalance. We can counter class imbalance by weighting the classes in the loss. For example, for flood mapping ~5-10% of the pixels represent parts of flood events while the rest is background. To meet the class imbalance, we can set the class weight of the flood class to, e.g., 90%, while the background class will be assigned a class weight of 10%. For segmentation on burn scars, there are only two classes, so only two class weights need to be specified.\n",
    "\n",
    "\n",
    "Example of Cross Entropy Loss options for burn scars:\n",
    "| Weight land class | Weight burn scar class | Code | \n",
    "| ------------------ | ----------------- | ---- |\n",
    "| 0.3 | 0.7 | `[0.7, 0.3]` |\n",
    "| 0.1 | 0.9 | `[0.9, 0.1]` |\n",
    "<!--     * cross entropy loss with weight water class = 0.7, weight land class = 0.3, weight cloud class = 0.0,\n",
    "    * cross entropy loss with weight water class = 0.9, weight land class = 0.1, weight cloud class = 0.0\n",
    "     -->\n",
    "\n",
    "**Learning rate**: Defines how much we want the model to change in response to the estimated error each time the model weights are updated. Options: `6e-4`, `6e-5`, `6e-6`\n",
    "\n",
    "**Auxiliary head**: To stabilize the finetuning process, the model not only includes an encoder and a decode head for segmentation, but also an auxiliary head. This part of the architecture helps to make the model more robust during finetuning. You can add and remove the auxiliary head using the boolean option: `aux_head=True`, `aux_head=False`\n",
    "\n",
    "**Depth of the decoder**: Generally, the decoder is quite light-weight compared to the GeoFM encoder. A default choice would be one or two layers of convolutions. Increasing this value will result in more parameters that the model can leverage to adapt to the downstream task -- at the cost of heavier computations (finetuning will take more time!). Options: `decode_head_conv = 1`, `decode_head_conv = 2`\n",
    "\n",
    "**Number of epochs**: Deep neural networks are typically require a certain number of epochs to converge. For example, in our experiments, we observed that the finetuning for flood mapping achieves a desirable level of fitness after ~40-50 epochs. *Please do not extend the number of epochs to more than 50 epochs to have a managable time for computations. :-)*\n",
    "\n",
    "### Setting up your experiment\n",
    "Now to set up your experiment options in `example_workflows/payload_mmseg.json` you wish to chose (based on the description above and discussions).  Don't edit the `num_epochs`, `batch_size`, `number_training_files` or `project_name`.\n",
    "\n",
    "You generate your config which places the options you have chosen into a configuration file, which you can then view using the next cell.\n",
    "\n",
    "------------------------------------------------\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e643a856-eb2b-4a6d-9401-b97ecb1ac7fd",
   "metadata": {},
   "source": [
    "# 2. Submitting fine-tuning job to run"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d82b2b13-2750-4ce4-8812-ab49a111768c",
   "metadata": {},
   "source": [
    "Now we have the configuration script ready, we can just send it to the cluster to run.  The next cell will submit the job to the cluster using TorchX.  This will spin up a now pod/container where the fine-tuning will run."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8964c71-221d-42a8-83db-fe9efe9962eb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Choose the workflow (i.e. slope_calc, ifm_standard)\n",
    "wf = 'mmseg-plus-inference'\n",
    "\n",
    "\n",
    "wfy, dag, input_files = geodn_modelling.parse_and_print(\n",
    "    workflow_file='./example_workflows/workflow_' + wf + '.py', \n",
    "    payload_file='./example_workflows/payload_' + wf + '.json'\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c27f8fa6-1703-474d-a3e5-a9dd47555706",
   "metadata": {},
   "source": [
    "The cell above should return a successful compilation and we can now visualise the workflow graph.  This will give you a first indication if you have constructed the graph you intended to.  In future, more detailed and interactive visualisations will be available."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f038f99-fc6f-4ed6-bb3c-6672694427f5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Optional step to view the DAG describe by the workflow template and payload together\n",
    "G = workflow.draw_workflow(dag)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a1436bb-8b9f-41ca-9dbd-232050800a29",
   "metadata": {
    "tags": []
   },
   "source": [
    "***\n",
    "# 2. Submit workflow to GeoDN Modeling cluster to run\n",
    "\n",
    "Once you have tested that your workflow function successfully ingests the user payload and generated the correct  graph, it is now time to run the workflow on a GeoDN Modeling cluster and check the outputs.\n",
    "\n",
    "To do this we will use the `parse_and_submit` function.  This is very similar to `parse_and_print` but will send it to the cluster (specified by the url at the top of the notebook).  The only additional argument you need to provide is a name to give your workflow instance.\n",
    "\n",
    "If the submission is successful, you should get a response which includes the `model_run_id` which is the main identifier linked to that run of the workflow.  You will use that later to check status, access logs and generated files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b36051d-a8ca-415b-89d8-c82c74386820",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Choose the workflow (i.e. slope_calc, ifm_standard)\n",
    "response = geodn_modelling.parse_and_submit(name=wf, \n",
    "                      workflow_file='./example_workflows/workflow_' + wf + '.py', \n",
    "                      payload_file='./example_workflows/payload_' + wf + '.json',\n",
    "                      )\n",
    "\n",
    "model_run_id = response['data']['model_run_id']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbb7e9d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(model_run_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a24c1321-9435-4db0-be2a-24f9ac805bc7",
   "metadata": {},
   "source": [
    "------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df609e38-ef76-40bc-aef2-fcf667215893",
   "metadata": {},
   "source": [
    "# 3. Monitor the workflow and check outputs\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f27f5603-cd83-4d2d-bba3-c8f7ea72c37a",
   "metadata": {
    "tags": []
   },
   "source": [
    "Once you have submitted the workflow to the cluster to run, you can monitoring its progress, by:\n",
    "\n",
    "### Checking the workflow status\n",
    "The `workflowStatus` function will (for a given `model_run_id`) show the status of the workflow run.  At present, this is the status of any steps which are/have been running.  You will see `Pending`, `Running`, `Succeeded` or `Failed`.  In the case of a failed step it will show an error message (this will often refer you to the logs, see below).  The json returned (`opr` here) contains more detailed information about when steps ran etc)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62377c00",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_run_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3258cbb8-05b0-4e89-a5df-ceb5752a59f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "opr = geodn_modelling.workflowStatus(model_run_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc782b4d-4488-4cec-87ed-b73c8d98ae6d",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Pulling the log files:\n",
    "\n",
    "Logs files for all steps in GeoDN Modeling workflows are archived in the same S3-compatible bucket where the data files reside.  This is an asynchronous process, so there is a delay in logs being available through the SDK (this could be up to 10 minutes currently).\n",
    "\n",
    "The GeoDN SDK `grab_logs` function will find the archived logs related to a given `model_run_id`, load them and clean them.  The `print_logs` will print extracted logs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09a26436-0f23-4a96-a35e-e37b4337f67a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "logs = geodn_modelling.grab_logs(model_run_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "291ae54c-251f-4aee-b549-31f94932c274",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "pod_logs = workflow.print_logs(logs, level='content')\n",
    "print(json.dumps(pod_logs, indent=1))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a3fe849-af00-4518-8768-5e066e53d140",
   "metadata": {
    "tags": []
   },
   "source": [
    "# 4. Downloading and checking output files\n",
    "In a GeoDN Modeling workflow, all the data files from a particular run of a workflow are stored in an S3-compitable bucket. This includes the input files, the final outputs and all intermediate files.  To check if the workflow has run correctly, we can check the correct files have been generated, download them and take a look.\n",
    "\n",
    "You can either access a list of non-log files from the workflow with `geodn_modelling.listWorkflowFiles(model_run_id)` and download the ones you want to look at with `geodn_modelling.downloadFiles()`.\n",
    "\n",
    "Or you could use the interactive downloader, where you can select multiple files, specify the download path in the box at the bottom and click the download button."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d31463cd-2bf5-4fcb-9b0c-c2b4797b5810",
   "metadata": {},
   "outputs": [],
   "source": [
    "workflow.fileDownloader(geodn_modelling, model_run_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65b7f140-2edc-4232-818c-6fafce98c04c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "geodn_modelling.listWorkflowFiles(model_run_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1d667b4-88c7-4d1e-b57c-12bc2a038ef9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "geodn_modelling.downloadFiles(f\"default/{model_run_id}/main/subsetted_512x512_HLS_pred.tif\")\n",
    "geodn_modelling.downloadFiles(f\"default/{model_run_id}/main/subsetted_512x512_HLS.S30.T10SEH.2018190.v1.4_inf_merged.tif\")\n",
    "\n",
    "for ofile in geodn_modelling.listWorkflowFiles(model_run_id):\n",
    "    if  ofile.split('log.')[-1] =='json':\n",
    "        geodn_modelling.downloadFiles(ofile)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d79c2caf-82b8-4137-80eb-ddd7ce540337",
   "metadata": {},
   "source": [
    "## Viewing the training metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fca8a53-6e53-4b4e-b18d-85d83a8c4bc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_tune_metrics():\n",
    "    log_name = glob.glob('*.log.json')\n",
    "\n",
    "    with open(log_name[0]) as fp:\n",
    "        lines = [line.rstrip('\\n') for line in fp]\n",
    "    metrics = [json.loads(X) for X in lines[1:]]\n",
    "\n",
    "    train_df = pd.DataFrame.from_records([d for d in metrics if d['mode']=='train'])\n",
    "    val_df = pd.DataFrame.from_records([d for d in metrics if d['mode']=='val'])\n",
    "    return train_df, val_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7ffca07-2ee2-4fb1-842c-0ffbfa33844f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import glob\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "log_name = glob.glob('*.log.json')\n",
    "\n",
    "with open(log_name[0]) as fp:\n",
    "    lines = [line.rstrip('\\n') for line in fp]\n",
    "metrics = [json.loads(X) for X in lines[1:]]\n",
    "\n",
    "# print(metrics)\n",
    "train_df = pd.DataFrame.from_records([d for d in metrics if d['mode']=='train'])\n",
    "val_df = pd.DataFrame.from_records([d for d in metrics if d['mode']=='val'])\n",
    "\n",
    "plt.figure(figsize=(20,10))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(train_df.index, train_df.loss, '-k');\n",
    "plt.xlabel('evaluation_interval');\n",
    "plt.ylabel('training loss');\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(val_df.index, val_df.aAcc, '-k');\n",
    "plt.xlabel('evaluation_interval');\n",
    "plt.ylabel('validation aAcc');"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae51ee64-dc33-4fbe-9fd6-826623241ab5",
   "metadata": {},
   "source": [
    "***\n",
    "# 5. Model inference"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b973dd38-98b1-43bf-83de-e8b4dce106ec",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "Once we have a trained model, we can use it to run inference on other images. This can also be done in a seperate workflow."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d069537e-dd12-499d-bc83-43a175b7a5cb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "inference_files = sorted(glob.glob('*pred.tif'))\n",
    "\n",
    "original_file = 'main_subsetted_512x512_HLS.S30.T10SEH.2018190.v1.4_inf_merged.tif'\n",
    "predict_file = 'main_subsetted_512x512_HLS_pred.tif'\n",
    "\n",
    "with rasterio.open(original_file) as src:\n",
    "    redArray = src.read(1)\n",
    "    redArray=redArray/np.max(redArray,axis=(0,1))\n",
    "    greenArray = src.read(2)\n",
    "    greenArray=greenArray/np.max(greenArray,axis=(0,1))\n",
    "    blueArray = src.read(3)\n",
    "    blueArray=blueArray/np.max(blueArray,axis=(0,1))\n",
    "    \n",
    "    im_rgb = np.array([redArray,greenArray,blueArray])\n",
    "    \n",
    "with rasterio.open(predict_file) as src:\n",
    "    pred=np.squeeze(src.read())\n",
    "    \n",
    "pyplot.title('Original image')\n",
    "show(im_rgb)\n",
    "pyplot.title('Prediction')\n",
    "pyplot.imshow(pred)\n",
    "\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81ddf920-f54c-47b0-b27e-e36dc2b48a3a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:godn]",
   "language": "python",
   "name": "conda-env-godn-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f939a6de-3c84-4953-982e-2d1063b2f8f4",
   "metadata": {},
   "source": [
    "# GeoDN Course 2: Fundamentals of Geospatial Data and Modeling - Part 2 Geospatial Foundation Models and Workflows #\n",
    "> Copyright (c) 2024 International Business Machines Corporation\n",
    "\n",
    "> This software is released under the MIT License.\n",
    "> https://opensource.org/licenses/MIT\n",
    "\n",
    "# Section 2 - Workflow development/testing and sharing\n",
    "This notebook will provide a walkthrough of using the GeoDN SDK to test and deploy a GeoDN modeling workflow.\n",
    "\n",
    "We will begin from the example workflows (in the `example_workflows` folder).  In GeoDN Modeling, workflows are defined by a python function which takes a user payload (as a dict) and dynamically generated both the workflow graph specification and the required input config files, generated based on the user options. \n",
    "\n",
    "You can take a look at the different examples and the documentation will describe the details about the anatomy of the workflow definition.\n",
    "\n",
    "The development/testing steps we will follow are to:\n",
    "1) Try passing a payload into a workflow function and check the generated workflow\n",
    "2) Send that payload to GeoDN Modeling to run\n",
    "3) Monitor the workflow status and check the logs \n",
    "4) Download and check the files generated by the workflow\n",
    "5) Submit workflow to the catalogue\n",
    "\n",
    "If the developer is happy with the workflow and would like to submit it to the GeoDN Modeling catalogue to share with others, we should the simple step of pushing to the workflow catalogue.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b87b1624-92e3-484f-8ba3-1bf53fd53b7b",
   "metadata": {},
   "source": [
    "### Prepare\n",
    "Load the `geodn.modeling` module. We also need to using the python package `os`, `json` and `Image` from `PIL`, so let's import those too.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8dec33b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from geodn.modeling import workflow\n",
    "\n",
    "import os\n",
    "import json\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41aec73e-8a52-4984-a880-53baeb29cf35",
   "metadata": {},
   "source": [
    "### Authenticate to GeoDN\n",
    "\n",
    "To authenticate to the GeoDN services, add your username and password to the file `~/geodn-creds`, which can be found in the home folder. The format should be `your-username:your-password`. \n",
    "\n",
    "Once updated, we can use the `getToken()` function to get an authentication token which will later be used to access the GeoDN services. The `get_token()` function takes three parameters, `username`, `password` and `geodn_modeling_url`, which are your username, your password and the URL of the GeoDN backend service to connect to, respecitvely. \n",
    "\n",
    "These tokens will expire after 24 hours. To also return a refresh_token, pass `refresh=True` to `getToken()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73278449-be14-40a1-a5ad-e822aeed7ad1",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"../..\" + '/geodn-creds', 'r') as file:\n",
    "    data = file.read().rstrip()\n",
    "    username = data.split(':')[0]\n",
    "    password = data.split(':')[1]\n",
    "\n",
    "assert username and password\n",
    "\n",
    "# Get the tokens\n",
    "id_token, access_token = workflow.get_token(username, password, geodn_modeling_url=os.environ[\"GEODN_URL\"])\n",
    "assert id_token and access_token"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b1c382e-d453-49e2-b422-6cf4855c793b",
   "metadata": {},
   "source": [
    "### Connect to GeoDN modeling\n",
    "\n",
    "And finally, we can connect to the GeoDN Modeling service. Here you will pass the token and create the connection to the GeoDN Modeling APIs. This will allow you to submit models to the cluster, check status, access logs and download files.\n",
    "\n",
    "To determine which backend service to connect to, we use the arguments `geodn_modeling_url`, `core_url` and `workflow_url`. These have been set as environment variables but can be configured if in the future you require a connection to a different backend service. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e67f153",
   "metadata": {},
   "outputs": [],
   "source": [
    "geodn_modelling = workflow.GeoDN_Modeling(\n",
    "    bearer_token=id_token,\n",
    "    api_url=os.environ[\"GEODN_URL\"],\n",
    "    core_url=os.environ[\"GEODN_CORE_URL\"],\n",
    "    workflow_url=os.environ[\"GEODN_WORKFLOW_URL\"],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da3e5a65",
   "metadata": {},
   "source": [
    "Sometimes, we can see errors returned from this function. If this is the case, it maybe that the `id_token` has expired and needs to be regenerated. Re-run the `get_token` function to generate a new token."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d82b2b13-2750-4ce4-8812-ab49a111768c",
   "metadata": {},
   "source": [
    "------------------------------------------------\n",
    "# 1. Passing a payload into a workflow function and check the generated workflow\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95e63b5c-7abf-45e3-b343-d9c704c84ede",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Test compile a workflow definition from file\n",
    "\n",
    "In order to generate a workflow to run in GeoDN Modeling, a user specifies their choices of parameters, datasets etc and submits them as a json/dict payload.\n",
    "\n",
    "The first step is to pass a payload into the workflow function to see if it is interpretted correctly.  We want to see that the payload is successully passed and the function is able to generate a workflow graph and any input files (if required).\n",
    "\n",
    "To do this we will chose a workflow and its corresponding payload (to start with use the examples, but feel free to start experimenting), and use the `parse_and_print` function to combine the two.  If the function generates a graph, it will then be compiled into the yaml which will eventually get sent to the orchestrator.  In general, you don't need to dig into this unless you are doing something very advanced, or there are bugs with a workflow which are otherwise hard to decipher.\n",
    "\n",
    "`parse_and_print` takes a workflow (either from file, or function name) and a payload (from file or dict) and returns the compiled workflow yaml (`wfy` below), the workflow graph (`dag`) and input files.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8964c71-221d-42a8-83db-fe9efe9962eb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Choose the workflow (i.e. slope_calc, ifm_standard)\n",
    "wf = 'air_pollution'\n",
    "\n",
    "\n",
    "wfy, dag, input_files = geodn_modelling.parse_and_print(\n",
    "    workflow_file='./example_workflows/workflow_' + wf + '.py', \n",
    "    payload_file='./example_workflows/payload_' + wf + '.json'\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c27f8fa6-1703-474d-a3e5-a9dd47555706",
   "metadata": {},
   "source": [
    "The cell above should return a successful compilation and we can now visualise the workflow graph.  This will give you a first indication if you have constructed the graph you intended to.  In future, more detailed and interactive visualisations will be available."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f038f99-fc6f-4ed6-bb3c-6672694427f5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Optional step to view the DAG describe by the workflow template and payload together\n",
    "G = workflow.draw_workflow(dag)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a794542c-f5ff-426f-8e87-117939381cd0",
   "metadata": {},
   "source": [
    "------------------------------------------------\n",
    "\n",
    "# 2. Send payload to GeoDN Modeling to run"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a1436bb-8b9f-41ca-9dbd-232050800a29",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Submit workflow to GeoDN Modeling cluster to run\n",
    "\n",
    "Once you have tested that your workflow function successfully ingests the user payload and generated the correct  graph, it is now time to run the workflow on a GeoDN Modeling cluster and check the outputs.\n",
    "\n",
    "To do this we will use the `parse_and_submit` function.  This is very similar to `parse_and_print` but will send it to the cluster (specified by the url at the top of the notebook).  The only additional argument you need to provide is a name to give your workflow instance.\n",
    "\n",
    "If the submission is successful, you should get a response which includes the `model_run_id` which is the main identifier linked to that run of the workflow.  You will use that later to check status, access logs and generated files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b36051d-a8ca-415b-89d8-c82c74386820",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = geodn_modelling.parse_and_submit(name=wf, \n",
    "                      workflow_file='./example_workflows/workflow_' + wf + '.py', \n",
    "                      payload_file='./example_workflows/payload_' + wf + '.json',\n",
    "                      )\n",
    "\n",
    "model_run_id = response['data']['model_run_id']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbb7e9d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(model_run_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27043eb8-302d-4341-8074-ba78b8ac7b08",
   "metadata": {},
   "source": [
    "------------------------------------------------\n",
    "#  3. Monitor the workflow and check outputs\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f27f5603-cd83-4d2d-bba3-c8f7ea72c37a",
   "metadata": {
    "tags": []
   },
   "source": [
    "Once you have submitted the workflow to the cluster to run, you can monitoring its progress, by:\n",
    "\n",
    "### Checking the workflow status\n",
    "The `workflowStatus` function will (for a given `model_run_id`) show the status of the workflow run.  At present, this is the status of any steps which are/have been running.  You will see `Pending`, `Running`, `Succeeded` or `Failed`.  In the case of a failed step it will show an error message (this will often refer you to the logs, see below).  The json returned (`opr` here) contains more detailed information about when steps ran etc)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62377c00",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_run_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3258cbb8-05b0-4e89-a5df-ceb5752a59f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "opr = geodn_modelling.workflowStatus(model_run_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc782b4d-4488-4cec-87ed-b73c8d98ae6d",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Pulling the log files:\n",
    "\n",
    "Logs files for all steps in GeoDN Modeling workflows are archived in the same S3-compatible bucket where the data files reside.  This is an asynchronous process, so there is a delay in logs being available through the SDK (this could be up to 10 minutes currently).\n",
    "\n",
    "The GeoDN SDK `grab_logs` function will find the archived logs related to a given `model_run_id`, load them and clean them.  The `print_logs` will print extracted logs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09a26436-0f23-4a96-a35e-e37b4337f67a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "logs = geodn_modelling.grab_logs(model_run_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "291ae54c-251f-4aee-b549-31f94932c274",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "pod_logs = workflow.print_logs(logs, level='content')\n",
    "print(json.dumps(pod_logs, indent=1))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71bb8013-9169-4b91-ad0c-7430415c0946",
   "metadata": {},
   "source": [
    "------------------------------------------------\n",
    "# 4. Download and checking output files\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a3fe849-af00-4518-8768-5e066e53d140",
   "metadata": {
    "tags": []
   },
   "source": [
    "In a GeoDN Modeling workflow, all the data files from a particular run of a workflow are stored in an S3-compitable bucket. This includes the input files, the final outputs and all intermediate files.  To check if the workflow has run correctly, we can check the correct files have been generated, download them and take a look.\n",
    "\n",
    "You can either access a list of non-log files from the workflow with `geodn_modelling.listWorkflowFiles(model_run_id)` and download the ones you want to look at with `geodn_modelling.downloadFiles()`.\n",
    "\n",
    "Or you could use the interactive downloader, where you can select multiple files, specify the download path in the box at the bottom and click the download button. Once the workflow has completed and the `workflowStatus` method returns `succeeded`, all the files will be available to download. This includes `'main_warrington_pm10_daily_forecast_plot.png'` which we'll use in the next section."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d31463cd-2bf5-4fcb-9b0c-c2b4797b5810",
   "metadata": {},
   "outputs": [],
   "source": [
    "geodn_modelling.listWorkflowFiles(model_run_id)\n",
    "# workflow.fileDownloader(geodn_modelling, model_run_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4270ce85-b0dd-40d7-8273-de74b8ae5839",
   "metadata": {},
   "outputs": [],
   "source": [
    "for ofile in geodn_modelling.listWorkflowFiles(model_run_id):\n",
    "    geodn_modelling.downloadFiles(ofile)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a547ac66-0512-4488-acab-ba3635c57310",
   "metadata": {},
   "source": [
    "### Plot output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb501691-dfd9-4d1d-a750-7d97cdff2a2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "img = Image.open('main_warrington_pm10_daily_forecast_plot.png').convert(\"RGB\")\n",
    "display(img)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee952b8d-0dc5-4828-90c2-56ffb8924545",
   "metadata": {},
   "source": [
    "------------------------------------------------\n",
    "# 5. Submit workflow to the catalogue"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9f9aa40-d6df-4bd7-9514-0841d2d99cac",
   "metadata": {},
   "source": [
    "\n",
    "Once you have checked your workflow runs correctly and produces the outputs you desired you can push it to the workflow catalogue where you can share it with others.  Once a workflow is stored in the catalogue, a user can run the model by providing only the payload.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e582546-281d-466a-b194-42fb28057981",
   "metadata": {},
   "source": [
    "To upload the workflow, you use the `uploadWorkflow` function which takes a name for the workflow (the key in the catalogue), the workflow and payload (in the same way as the above previous functions), tags (optional) which can help to catagorise or search for workflows.  Finally, there is a flag to actually push it to the catalogue.  If the `upload` flag is not set to True, the function will grab the definitions, encode them and prepare the upload payload, but just not send it.  This is a useful check to do before uploading.\n",
    "\n",
    "Set `upload` to `True` to upload your workflow."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12917bad-3e76-49d3-9c1d-b891ae78907f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "upload = False\n",
    "\n",
    "geodn_modelling.upload_workflow(\n",
    "    'explain_air_pollution_v1', \n",
    "    workflow_file='example_workflows/workflow_' + wf + '.py', \n",
    "    payload_file='example_workflows/payload_' + wf + '.json', \n",
    "    tags=['explain'], \n",
    "    upload=upload)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20a7376d-6623-48c2-9949-37ec6b9d8a06",
   "metadata": {},
   "source": [
    "After uploading, you can check the workflow catalogue for the newly uploaded definition.  To do this you can use either the `cw.available_workflows()` and explore the dataframe that's returned, or you can use the searchable UI with `cw.available_workflows_ui()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9caf38d-532b-4d2b-8b45-df53b4c8fb85",
   "metadata": {},
   "outputs": [],
   "source": [
    "geodn_modelling.available_workflows_ui()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71d61a1f-fbbf-4a0f-8d12-e2f0421969fc",
   "metadata": {},
   "source": [
    "## Delete workflows\n",
    "To remove a workflow from the catalogue once it has been uploaded, the `delete_workflow()` function can be used to send a request to the GeoDN API to delete the specified workflow. Identify the workflow key and version number of the workflow you wish to delete using the `workflow_name` and `version` parameters respectively. You will only be able to remove workflow your user has previously uploaded."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f386ec7c-0f5e-435f-badb-1dbe7be595ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "geodn_modelling.delete_workflow(workflow_name=\"explain_air_pollution_v1\", version=\"20231101-5\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
